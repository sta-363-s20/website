<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Trade-offs: Accuracy and interpretability, bias and variance</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr.Â Dâ€™Agostino McGowan" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Trade-offs: Accuracy and interpretability, bias and variance
### Dr.Â Dâ€™Agostino McGowan

---






layout: true

&lt;div class="my-footer"&gt;
&lt;span&gt;
Dr. Lucy D'Agostino McGowan &lt;i&gt;adapted from slides by Hastie &amp; Tibshirani&lt;/i&gt;
&lt;/span&gt;
&lt;/div&gt; 

---



## Regression and Classification

* Regression: quantitative response
* Classification: qualitative (categorical) response

---

## Regression and Classification

.question[
What would be an example of a **regression** problem?
]

* Regression: quantitative response
* Classification: qualitative (categorical) response

---


## Regression and Classification

.question[
What would be an example of a **classification** problem?
]

* Regression: quantitative response
* Classification: qualitative (categorical) response

---

class: center, middle

# Regression

---

## Auto data


![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

Above are `mpg` vs `horsepower`, `weight`, and `acceleration`, with a blue linear-regression line fit separately to each. Can we predict `mpg` using these three?

--

Maybe we can do better using a model:

`\(\texttt{mpg} \approx f(\texttt{horsepower}, \texttt{weight}, \texttt{acceleration})\)`

---

## Notation

* `mpg` is the **response** variable, the **outcome** variable, we refer to this as `\(Y\)`
* `horsepower` is a **feature**, **input**, **predictor**, we refer to this as `\(X_1\)`
* `weight` is `\(X_2\)`
* `acceleration` is `\(X_3\)`
--

* Our **input vector** is

`$$X = \begin{bmatrix} X_1 \\X_2 \\X_3\end{bmatrix}$$`
--

* Our **model** is

`$$Y = f(X) + \epsilon$$`
* `\(\epsilon\)` is our error

---

## Why do we care about `\(f(X)\)`?

* We can use `\(f(X)\)` to make predictions of `\(Y\)` for new values of `\(X = x\)`
--

* We can gain a better understanding of which components of `\(X = (X_1, X_2, \dots, X_p)\)` are important for explaining `\(Y\)`
--

* Depending on how complex `\(f\)` is, maybe we can understand how each component ( `\(X_j\)` ) of `\(X\)` affects `\(Y\)`

---

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
How do we choose `\(f(X)\)`? What is a good value for
`\(f(X)\)` at any selected value of `\(X\)`, say `\(X = 100\)`? There can be many `\(Y\)` values at `\(X = 100\)`. 
--

A good value is

`$$f(100) = E(Y|X = 100)$$`

--

`\(E(Y|X = 100)\)` means **expected value** (average) of `\(Y\)` given `\(X = 100\)`

--

This ideal `\(f(x) = E(Y | X = x)\)` is called the **regression function**

---

## Regression function, `\(f(X)\)`

* Also works or a vector, `\(X\)`, for example,

`$$f(x) = f(x_1, x_2, x_3) = E[Y | X_1 = x_1, X_2 = x_2, X_3 = x_3]$$`

* This is the **optimal** predictor of `\(Y\)` in terms of **mean-squared prediction error**
--

.definition[
`\(f(x) = E(Y|X = x)\)` is the function that **minimizes** `\(E[(Y - g(X))^2 |X = x]\)` over all
functions `\(g\)` at all points `\(X = x\)`
]

--
* `\(\epsilon = Y - f(x)\)` is the **irreducible error** 
* even if we knew `\(f(x)\)`, we would still make errors in prediction, since at each `\(X = x\)` there is typically a distribution of possible `\(Y\)` values

---

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

---

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;



.question[
Using these points, how would I calculate the **regression function**?
]

--
* Take the average! `\(f(100) = E[\texttt{mpg}|\texttt{horsepower} = 100] = 19.6\)`

---

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

.question[
This point has a `\(Y\)` value of 32.9. What is `\(\epsilon\)`?
]

--

* `\(\epsilon = Y - f(X) = 32.9 - 19.6 = \color{red}{13.3}\)`

---

## The error

For any estimate, `\(\hat{f}(x)\)`, of `\(f(x)\)`, we have

`$$E[(Y - \hat{f}(x))^2 | X = x] = \underbrace{[f(x) - \hat{f}(x)]^2}_{\textrm{reducible error}} + \underbrace{Var(\epsilon)}_{\textrm{irreducible error}}$$`

---

## Estimating `\(f\)`

* Typically we have very few (if any!) data points at `\(X=x\)` exactly, so we cannot compute `\(E[Y|X=x]\)`
--

* For example, what if we were interested in estimating miles per gallon when horsepower was 104.

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
--

ðŸ’¡ We can _relax_ the definition and let

`$$\hat{f}(x) = E[Y | X\in \mathcal{N}(x)]$$`

---

## Estimating `\(f\)`

* Typically we have very few (if any!) data points at `\(X=x\)` exactly, so we cannot compute `\(E[Y|X=x]\)`
* For example, what if we were interested in estimating miles per gallon when horsepower was 104.

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

ðŸ’¡ We can _relax_ the definition and let

`$$\hat{f}(x) = E[Y | X\in \mathcal{N}(x)]$$`

* Where `\(\mathcal{N}(x)\)` is some **neighborhood** of `\(x\)`

---

## Notation pause!

&lt;br&gt;&lt;br&gt;&lt;br&gt;

`$$\hat{f}(x) = \underbrace{E}_{\textrm{The expectation}}[\underbrace{Y}_{\textrm{of Y}} \underbrace{|}_{\textrm{given}} \underbrace{X\in \mathcal{N}(x)}_{\textrm{X is in the neighborhood of x}}]$$`
--

.alert[
If you need a notation pause at any point during this class, please let me know! 
]

---

## Estimating `\(f\)`

ðŸ’¡ We can _relax_ the definition and let

`$$\hat{f}(x) = E[Y | X\in \mathcal{N}(x)]$$`

--
* Nearest neighbor averaging does pretty well with small `\(p\)` ( `\(p\leq 4\)` ) and large `\(n\)`

--
* Nearest neighbor is _not great_ when `\(p\)` is large because of the **curse of dimensionality** (because nearest neighbors tend to be far away in high dimensions)

--
.question[
What do I mean by `\(p\)`? What do I mean by `\(n\)`?
]

---

## Parametric models

A common parametric model is a **linear** model

`$$f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p$$`

--
* A linear model has `\(p + 1\)` parameters ( `\(\beta_0,\dots,\beta_p\)` )

--
* We estimate these parameters by **fitting** a model to **training** data

--
* Although this model is _almost never correct_ it can often be a good interpretable approximation to the unknown true function, `\(f(X)\)`

---

class: center, middle

## Let's look at a simulated example

---

&lt;center&gt;
&lt;img src = "img/03/sim1.png" height = "400"&gt; &lt;/img&gt;
&lt;/center&gt;

* The &lt;font color = "red"&gt; red &lt;/font&gt; points are simulated values for `income` from the model:

`$$\texttt{income} = f(\texttt{education, senority}) + \epsilon$$`
* `\(f\)` is the &lt;font color = "blue"&gt; blue &lt;/font&gt; surface

---

&lt;center&gt;
&lt;img src = "img/03/sim2.png" height = "400"&gt; &lt;/img&gt;
&lt;/center&gt;

Linear regression model fit to the simulated data

`$$\hat{f}_L(\texttt{education, senority}) = \hat{\beta}_0 + \hat{\beta}_1\texttt{education}+\hat{\beta}_2\texttt{senority}$$`

---

&lt;center&gt;
&lt;img src = "img/03/sim3.png" height = "400"&gt; &lt;/img&gt;
&lt;/center&gt;

* More flexible regression model `\(\hat{f}_S(\texttt{education, seniority})\)` fit to the simulated data
* Here we use a technique called a **thin-plate spline** to fit a flexible surface

---

&lt;center&gt;
&lt;img src = "img/03/sim4.png" height = "400"&gt; &lt;/img&gt;
&lt;/center&gt;

And even **MORE flexible** ðŸ˜± model `\(\hat{f}(\texttt{education, seniority})\)`
* Here we've basically drawn the surface to hit every point, minimizing the error, but completely **overfitting**

---

## ðŸ¤¹ Finding balance

* **Prediction accuracy** versus **interpretability**
* Linear models are easy to interpret, thin-plate splines
are not
--

* Good fit versus **overfit** or **underfit**
* How do we know when the fit is just right?
--

* **Parsimony** versus **black-box**
* We often prefer a simpler model involving fewer variables over a black-box predictor involving them all

---

![](img/03/flex.png)

---

## Accuracy

* We've fit a model `\(\hat{f}(x)\)` to some training data `\(\texttt{train} = \{x_i, y_i\}^N_1\)`
* We can measure **accuracy** as the average squared prediction error over that `train` data

`$$MSE_{\texttt{train}} = \textrm{Ave}_{i\in\texttt{train}}[y_i-\hat{f}(x_i)]^2$$`
--

.question[
What can go wrong here? 
]

--
* This may be biased towards **overfit** models

---

## Accuracy


![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

.question[
I have some `train` data, plotted above. What `\(\hat{f}(x)\)` would minimize the `\(MSE_{\texttt{train}}\)`?
]

`$$MSE_{\texttt{train}} = \textrm{Ave}_{i\in\texttt{train}}[y_i-\hat{f}(x_i)]^2$$`

---

## Accuracy 

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;

.question[
I have some `train` data, plotted above. What `\(\hat{f}(x)\)` would minimize the `\(MSE_{\texttt{train}}\)`?
]

`$$MSE_{\texttt{train}} = \textrm{Ave}_{i\in\texttt{train}}[y_i-\hat{f}(x_i)]^2$$`

---

## Accuracy 

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

.question[
What is wrong with this?
]

--

It's **overfit!**

---

## Accuracy

![](03-notation-and-tradeoffs_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

If we get a new sample, that overfit model is probably going to be terrible!

---

## Accuracy

* We've fit a model `\(\hat{f}(x)\)` to some training data `\(\texttt{train} = \{x_i, y_i\}^N_1\)`
* Instead of measuring **accuracy** as the average squared prediction error over that `train` data, we can compute it using fresh `test` data $\texttt{test} = \{x_i,y_i\}^M_1

`$$MSE_{\texttt{test}} = \textrm{Ave}_{i\in\texttt{test}}[y_i-\hat{f}(x_i)]^2$$`

---

![](img/03/mse1.png)

Black curve is the "truth" on the left. &lt;font color="red"&gt; Red &lt;/font&gt; curve on right is `\(MSE_{\texttt{test}}\)`, &lt;font color="grey"&gt;grey &lt;/font&gt;curve is `\(MSE_{\texttt{train}}\)`. &lt;font color="orange"&gt;Orange&lt;/font&gt;, &lt;font color="blue"&gt;blue &lt;/font&gt;and &lt;font color="green"&gt;green &lt;/font&gt;curves/squares correspond to fis of different flexibility.
---

![](img/03/mse2.png)

Here the truth is smoother, so the smoother fit and linear model do
really well
---

![](img/03/mse3.png)

Here the truth is wiggly and the noise is low, so the more flexible fits do the best
---

## Bias-variance trade-off

* We've fit a model, `\(\hat{f}(x)\)`, to some training data
--

* Let's pull a test observation from this population ( `\(x_0, y_0\)` )
--

* The _true_ model is `\(Y = f(x) + \epsilon\)`
--

* `\(f(x) = E[Y|X=x]\)`

`$$E(y_0 - \hat{f}(x_0))^2 = \textrm{Var}(\hat{f}(x_0)) + [\textrm{Bias}(\hat{f}(x_0))]^2 + \textrm{Var}(\epsilon)$$`

--

The expectation averages over the variability of `\(y_0\)` as well as the variability of the training data. `\(\textrm{Bias}(\hat{f}(x_0)) =E[\hat{f}(x_0)]-f(x_0)\)`

* As **flexibility** of `\(\hat{f}\)` `\(\uparrow\)`, its variance `\(\uparrow\)` and its bias `\(\downarrow\)`

--
* choosing the flexibility based on average test error amounts to a **bias-variance trade-off**

---

## Bias-variance trade-off

![](img/03/bias-var.png)

---

class: center, middle

# Classification

---

## Notation

* `\(Y\)` is the response variable. It is **qualitative**
* `\(\mathcal{C}(X)\)` is the classifier that assigns a class `\(\mathcal{C}\)` to some future unlabeled observation, `\(X\)`
--

* Examples:
  * Email can be classified as `\(\mathcal{C}=(\texttt{spam, not spam})\)`
  * Written number is one of `\(\mathcal{C}=\{0, 1, 2, \dots, 9\}\)`

---

## Classification Problem

.question[
What is the goal?
]

--

* Build a classifier `\(\mathcal{C}(X)\)` that assigns a class label from `\(\mathcal{C}\)` to a future unlabeled observation `\(X\)`
* Assess the uncertainty in each classification
* Understand the roles of the different predictors among `\(X = (X_1, X_2, \dots, X_p)\)`

---

&lt;center&gt;
&lt;img src = "img/03/class1.png" height = 275&gt;&lt;/img&gt;
&lt;/center&gt;

Suppose there are `\(K\)` elements in `\(\mathcal{C}\)`, numbered `\(1, 2, \dots, K\)`

`$$p_k(x) = P(Y = k|X=x), k = 1, 2, \dots, K$$`
These are **conditional class probabilities** at `\(x\)`

--
* The **Bayes optimal classifier** at `\(x\)` is

`$$\mathcal{C}(x) = j \textrm{ if } p_j(x) = \textrm{max}\{p_1(x), p_2(x), \dots, p_K(x)\}$$`

--
.question[
How do you think we could calculate this?
]

---

&lt;center&gt;
&lt;img src = "img/03/class1.png" height = 275&gt;&lt;/img&gt;
&lt;/center&gt;

Suppose there are `\(K\)` elements in `\(\mathcal{C}\)`, numbered `\(1, 2, \dots, K\)`

`$$p_k(x) = P(Y = k|X=x), k = 1, 2, \dots, K$$`
These are **conditional class probabilities** at `\(x\)`

* The **Bayes optimal classifier** at `\(x\)` is

`$$\mathcal{C}(x) = j \textrm{ if } p_j(x) = \textrm{max}\{p_1(x), p_2(x), \dots, p_K(x)\}$$`

* In the plot, you could examine the mini-barplot at `\(x = 5\)`

---

&lt;center&gt;
&lt;img src = "img/03/class2.png" height = 275&gt;&lt;/img&gt;
&lt;/center&gt;

.question[
What if this was our data and there were no points at exactly `\(x = 5\)`? Then how could we calculate this?
]

--

* Nearest neighbor like before!
--

* This does break down as the dimensions grow, but the impact of `\(\mathcal{\hat{C}}(x)\)` is less than on `\(\hat{p}_k(x), k = 1,2,\dots,K\)`

---

## Accuracy

* Misclassification error rate

`$$Err_{\texttt{test}} = \textrm{Ave}_{i\in\texttt{test}}I[y_i\neq \mathcal{\hat{C}}(x_i)]$$`

--
* The **Bayes Classifier** using the try `\(p_k(x)\)` has the smallest error

--
* Some of the methods we will learn build structured models for `\(\mathcal{C}(x)\)` (support vector machines, for example)

--
* Some build structured models for `\(p_k(x)\)` (logistic regression, for example)

---

## K-Nearest-Neighbors example

&lt;img src = "img/03/knn1.png" height = 450&gt;&lt;/img&gt;

---

## KNN (K = 10)

&lt;img src = "img/03/knn2.png" height = 450&gt;&lt;/img&gt;

---

## KNN

![](img/03/knn3.png)

---

## Trade-offs

![](img/03/errors.png)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
